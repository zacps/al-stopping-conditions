{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from importlib import reload\n",
    "from functools import partial, lru_cache\n",
    "import itertools\n",
    "from time import monotonic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import delayed\n",
    "from modAL import batch\n",
    "from art.metrics import empirical_robustness\n",
    "from art.attacks.evasion import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnSVC\n",
    "from sklearn.metrics.pairwise import paired_distances, euclidean_distances\n",
    "import scipy\n",
    "from tvregdiff.tvregdiff import TVRegDiff\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import libactive\n",
    "import libadversarial\n",
    "import libstop\n",
    "from libactive import MyActiveLearner, active_split\n",
    "from libadversarial import adversarial, uncertainty, random_batch, uncertainty_stop\n",
    "from libutil import ProgressParallel\n",
    "from libdatasets import *\n",
    "import librun\n",
    "from librun import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libdatasets; reload(libdatasets); from libdatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        #(\"newsgroups\", wrap(newsgroups, None)),\n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        \n",
    "        # Image classification\n",
    "        (\"cifar10\", wrap(cifar10, None)),\n",
    "        (\"quickdraw\", wrap(quickdraw, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        \n",
    "        # General\n",
    "        (\"shuttle\", wrap(shuttle, None)),\n",
    "        #(\"covertype\", wrap(covertype, None)), # fit takes a million years (1233s for 1000 instances)\n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"htru2\", wrap(htru2, None)),\n",
    "        #(\"malware\", wrap(malware, None)), # MALWARE FIT DID NOT FINISH (07:30:30.xxx CPU time)\n",
    "        (\"bidding\", wrap(bidding, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"bank\", wrap(bank, None)),\n",
    "        #(\"buzz\", wrap(buzz, None)), # Slow fit times\n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"dota2\", wrap(dota2, None)),\n",
    "        \n",
    "        # Bio\n",
    "        (\"abalone\", wrap(abalone, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),\n",
    "        \n",
    "        # Medical\n",
    "        (\"cardio\", wrap(cardio, None)),\n",
    "        (\"skin\", wrap(skin, None)),\n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": {\n",
    "            \"newsgroups_faith\": 500,\n",
    "            \"newsgroups_graphics\": 500,\n",
    "            \"newsgroups_hardware\": 500,\n",
    "            \"newsgroups_sports_crypto\": 500,\n",
    "            \"*\": 0.5\n",
    "        },\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "import operator\n",
    "import nesi_bias\n",
    "reload(nesi_bias)\n",
    "reload(libactive); from libactive import active_split\n",
    "from nesi_bias import bias\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "def func(model):\n",
    "    results = []\n",
    "    for (name, dataset) in tqdm(matrix['datasets']):\n",
    "        #print(f\"{name}\")\n",
    "        X, y = dataset()\n",
    "\n",
    "        try:\n",
    "            X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, y_test = active_split(\n",
    "                *dataset(), mutator=matrix['dataset_mutators']['none'], test_size=0.5, labeled_size=10, shuffle=True, random_state=np.random\n",
    "            )\n",
    "            assert X_unlabelled.shape[0] >= 1490, \"unlabelled pool too small\"\n",
    "        except Exception as e:\n",
    "            #print(f\"Could not split: {e}\")\n",
    "            results.append([name, 0,0,0])\n",
    "            continue\n",
    "\n",
    "        if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "            X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "        else:\n",
    "            X = np.concatenate((X_labelled, X_unlabelled))\n",
    "        y = np.concatenate((Y_labelled, Y_oracle))\n",
    "\n",
    "\n",
    "        clf = model()\n",
    "\n",
    "        clf.fit(X_labelled, Y_labelled)\n",
    "        start = clf.score(X_test, y_test)\n",
    "        start_t = monotonic()\n",
    "        clf.fit(X[:1000], y[:1000])\n",
    "        time = monotonic() - start_t\n",
    "        final = clf.score(X_test, y_test)\n",
    "        results.append([name, start, final, time])\n",
    "        \n",
    "    results = np.array(results)\n",
    "    print(tabulate(np.hstack((results, np.expand_dims(results[:,2].astype(float)-results[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce5e7a8d2034a3cb74b51c9861c2fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name            Initial acc    Final acc    Time         Diff\n",
      "------------  -------------  -----------  ------  -----------\n",
      "rcv1               0.474062     0.902694   3.093   0.428633\n",
      "webkb              0.298571     0.881429   3.172   0.582857\n",
      "spamassassin       0.742895     0.967284   2.375   0.224389\n",
      "cifar10            0.1394       0.300567   7.453   0.161167\n",
      "quickdraw          0.559482     0.75118    0.969   0.191698\n",
      "avila              0.177497     0.577918   0.25    0.400422\n",
      "shuttle            0.926138     0.970517   0.031   0.0443793\n",
      "smartphone         0.619327     0.940154   0.25    0.320827\n",
      "htru2              0.949156     0.979327   0.015   0.030171\n",
      "bidding            0.888326     0.989244   0.078   0.100917\n",
      "swarm              0.667971     0.942622   3.312   0.27465\n",
      "bank               0.883084     0.875697   0.328  -0.00738742\n",
      "sensorless         0.178978     0.869219   0.297   0.690241\n",
      "dota2              0.495143     0.563433   7.25    0.0682896\n",
      "abalone            0.438966     0.519387   0.344   0.0804213\n",
      "splice             0.592476     0.918495   0.75    0.326019\n",
      "anuran             0.758755     0.931907   0.062   0.173152\n",
      "cardio             0.597257     0.616429   0.094   0.0191714\n",
      "skin               0.793951     0.883032   0.031   0.089081\n"
     ]
    }
   ],
   "source": [
    "func(partial(SVC, kernel='linear', probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(MLPClassifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
