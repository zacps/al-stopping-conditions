{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from importlib import reload\n",
    "from functools import partial, lru_cache\n",
    "import itertools\n",
    "from time import monotonic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import delayed\n",
    "from modAL import batch\n",
    "from art.metrics import empirical_robustness\n",
    "from art.attacks.evasion import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnSVC\n",
    "from sklearn.metrics.pairwise import paired_distances, euclidean_distances\n",
    "import scipy\n",
    "from tvregdiff.tvregdiff import TVRegDiff\n",
    "from tabulate import tabulate\n",
    "\n",
    "from ipynb.fs.defs import Bias\n",
    "from ipynb.fs.defs.Datasets import generateData_twoPills_2D, generateData_twoPills_noNoise_2D, plot_dataset_2D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import libactive\n",
    "import libadversarial\n",
    "import libstop\n",
    "from libactive import MyActiveLearner, active_split\n",
    "from libadversarial import adversarial, uncertainty, random_batch, uncertainty_stop\n",
    "from libutil import ProgressParallel\n",
    "from libdatasets import *\n",
    "import librun\n",
    "from librun import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        # Text classification\n",
    "        \n",
    "\n",
    "        (\"newsgroups\", wrap(newsgroups, None)),    \n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        \n",
    "        # Image classification\n",
    "        (\"cifar10\", wrap(cifar10, None)),\n",
    "        (\"quickdraw\", wrap(quickdraw, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        \n",
    "        # General\n",
    "        (\"shuttle\", wrap(shuttle, None)),\n",
    "        (\"covertype\", wrap(covertype, None)), \n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"htru2\", wrap(htru2, None)),\n",
    "        (\"malware\", wrap(malware, None)), \n",
    "        (\"bidding\", wrap(bidding, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"bank\", wrap(bank, None)),\n",
    "        (\"buzz\", wrap(buzz, None)), \n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"dota2\", wrap(dota2, None)),\n",
    "        \n",
    "        # Bio\n",
    "        (\"abalone\", wrap(abalone, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),\n",
    "        \n",
    "        # Medical\n",
    "        (\"cardio\", wrap(cardio, None)),\n",
    "        (\"skin\", wrap(skin, None)),\n",
    "        \n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": {\n",
    "            \"newsgroups_faith\": 500,\n",
    "            \"newsgroups_graphics\": 500,\n",
    "            \"newsgroups_hardware\": 500,\n",
    "            \"newsgroups_sports_crypto\": 500,\n",
    "            \"*\": 0.5\n",
    "        },\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DATASET_DIR'] = r'C:\\Users\\Zac\\Programming\\python\\research\\datasets\\cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroups\n",
      "rcv1\n",
      "webkb\n",
      "spamassassin\n",
      "cifar10\n",
      "quickdraw\n",
      "avila\n",
      "shuttle\n",
      "covertype\n",
      "smartphone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htru2\n",
      "malware\n",
      "bidding\n",
      "swarm\n",
      "bank\n",
      "buzz\n",
      "sensorless\n",
      "dota2\n",
      "abalone\n",
      "splice\n",
      "anuran\n",
      "cardio\n",
      "skin\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "results = []\n",
    "for (name, dataset) in matrix['datasets']:\n",
    "    print(name)\n",
    "    #if name != \"spamassassin\": continue\n",
    "    X, y = dataset()\n",
    "    X = StandardScaler(with_mean=not isinstance(X, scipy.sparse.csr_matrix)).fit_transform(X)\n",
    "    \n",
    "    idx = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    \n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    y_short = y[:10]\n",
    "    X_short = X[:10]\n",
    "    for klass in np.unique(y):\n",
    "        if klass not in y_short:\n",
    "            idx = np.where(y==klass)[0][0]\n",
    "            y_short = np.concatenate((y_short, [y[idx]]), axis=0)\n",
    "            if isinstance(X_short, scipy.sparse.csr_matrix):\n",
    "                X_short = scipy.sparse.vstack((\n",
    "                    X_short, \n",
    "                    X[idx]\n",
    "                ))\n",
    "            else:\n",
    "                X_short = np.concatenate((X_short, [X[idx]]), axis=0)\n",
    "    #print(np.unique(y_short))\n",
    "\n",
    "    clf.fit(X_short, y_short)\n",
    "    start = clf.score(X[-1000:], y[-1000:])\n",
    "    start_t = monotonic()\n",
    "    clf.fit(X[:1000], y[:1000])\n",
    "    time = monotonic() - start_t\n",
    "    final = clf.score(X[-1000:], y[-1000:])\n",
    "    results.append([name, start, final, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            Initial acc    Final acc    Time    Diff\n",
      "------------  -------------  -----------  ------  ------\n",
      "newsgroups            0.041        0.099   9.609   0.058\n",
      "rcv1                  0.511        0.84    3.094   0.329\n",
      "webkb                 0.208        0.67    9.359   0.462\n",
      "spamassassin          0.336        0.966  11.344   0.63\n",
      "cifar10               0.149        0.285   8.844   0.136\n",
      "quickdraw             0.569        0.785   0.64    0.216\n",
      "avila                 0.271        0.556   0.266   0.285\n",
      "shuttle               0.905        0.981   0.032   0.076\n",
      "covertype             0.39         0.71    0.328   0.32\n",
      "smartphone            0.639        0.927   0.313   0.288\n",
      "htru2                 0.964        0.977   0.015   0.013\n",
      "malware               0.89         0.97    0.422   0.08\n",
      "bidding               0.898        0.899   0.375   0.001\n",
      "swarm                 0.721        0.999   3.438   0.278\n",
      "bank                  0.877        0.865   0.421  -0.012\n",
      "buzz                  0.741        0.916   0.156   0.175\n",
      "sensorless            0.157        0.877   0.297   0.72\n",
      "dota2                 0.519        0.57    5.688   0.051\n",
      "abalone               0.507        0.516   0.188   0.009\n",
      "splice                0.589        0.904   1.015   0.315\n",
      "anuran                0.781        0.967   0.062   0.186\n",
      "cardio                0.489        0.621   0.11    0.132\n",
      "skin                  0.869        0.869   0.031   0\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(np.hstack((results, np.expand_dims(results[:,2].astype(float)-results[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "results_not_norm = []\n",
    "for (name, dataset) in matrix['datasets']:\n",
    "    if name == \"malware\" or name == \"covertype\":\n",
    "        results_not_norm.append([name, 0, 0, 0])\n",
    "        continue\n",
    "        \n",
    "    X, y = dataset()\n",
    "    #X = StandardScaler(with_mean=not isinstance(X, scipy.sparse.csr_matrix)).fit_transform(X)\n",
    "    \n",
    "    idx = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    \n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    y_short = y[:10]\n",
    "    X_short = X[:10]\n",
    "    for klass in np.unique(y):\n",
    "        if klass not in y_short:\n",
    "            idx = np.where(y==klass)[0][0]\n",
    "            y_short = np.concatenate((y_short, [y[idx]]), axis=0)\n",
    "            if isinstance(X_short, scipy.sparse.csr_matrix):\n",
    "                X_short = scipy.sparse.vstack((\n",
    "                    X_short, \n",
    "                    X[idx]\n",
    "                ))\n",
    "            else:\n",
    "                X_short = np.concatenate((X_short, [X[idx]]), axis=0)\n",
    "    #print(np.unique(y_short))\n",
    "\n",
    "    clf.fit(X_short, y_short)\n",
    "    start = clf.score(X[-1000:], y[-1000:])\n",
    "    start_t = monotonic()\n",
    "    clf.fit(X[:1000], y[:1000])\n",
    "    time = monotonic() - start_t\n",
    "    final = clf.score(X[-1000:], y[-1000:])\n",
    "    results_not_norm.append([name, start, final, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            Initial acc    Final acc    Time    Diff\n",
      "------------  -------------  -----------  ------  ------\n",
      "newsgroups            0.066        0.405   9.781   0.339\n",
      "rcv1                  0.482        0.919   2.812   0.437\n",
      "webkb                 0.424        0.9     3.578   0.476\n",
      "spamassassin          0.781        0.968   2.078   0.187\n",
      "cifar10               0.137        0.284   7.875   0.147\n",
      "quickdraw             0.486        0.778   0.672   0.292\n",
      "avila                 0.256        0.589   0.25    0.333\n",
      "shuttle               0.915        0.968   0.89    0.053\n",
      "covertype             0            0       0       0\n",
      "smartphone            0.437        0.937   0.266   0.5\n",
      "htru2                 0.969        0.979   0.781   0.01\n",
      "malware               0            0       0       0\n",
      "bidding               0.903        0.985   0.078   0.082\n",
      "swarm                 0.635        0.962   3.531   0.327\n",
      "bank                  0.891        0.882   0.297  -0.009\n",
      "buzz                  0.942        0.987  38.843   0.045\n",
      "sensorless            0.084        0.391  12.328   0.307\n",
      "dota2                 0.481        0.569   7.719   0.088\n",
      "abalone               0.411        0.552   0.469   0.141\n",
      "splice                0.557        0.909   0.797   0.352\n",
      "anuran                0.507        0.951   0.078   0.444\n",
      "cardio                0.545        0.608   0.703   0.063\n",
      "skin                  0.925        0.88    2.719  -0.045\n"
     ]
    }
   ],
   "source": [
    "results_not_norm = np.array(results_not_norm)\n",
    "print(tabulate(np.hstack((results_not_norm, np.expand_dims(results_not_norm[:,2].astype(float)-results_not_norm[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.hstack((results, np.expand_dims(results[:,2].astype(float)-results[:,1].astype(float), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_not_norm = np.hstack((results_not_norm, np.expand_dims(results_not_norm[:,2].astype(float)-results_not_norm[:,1].astype(float), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized results - non normalized results\n",
      "Time positive = normalized slower \n",
      "Diff positive = normalized improved more\n",
      "\n",
      "Name            Time Diff    Diff\n",
      "------------  -----------  ------\n",
      "newsgroups         -0.172  -0.281\n",
      "rcv1                0.282  -0.108\n",
      "webkb               5.781  -0.014\n",
      "spamassassin        9.266   0.443\n",
      "cifar10             0.969  -0.011\n",
      "quickdraw          -0.032  -0.076\n",
      "avila               0.016  -0.048\n",
      "shuttle            -0.858   0.023\n",
      "covertype           0.328   0.32\n",
      "smartphone          0.047  -0.212\n",
      "htru2              -0.766   0.003\n",
      "malware             0.422   0.08\n",
      "bidding             0.297  -0.081\n",
      "swarm              -0.093  -0.049\n",
      "bank                0.124  -0.003\n",
      "buzz              -38.687   0.13\n",
      "sensorless        -12.031   0.413\n",
      "dota2              -2.031  -0.037\n",
      "abalone            -0.281  -0.132\n",
      "splice              0.218  -0.037\n",
      "anuran             -0.016  -0.258\n",
      "cardio             -0.593   0.069\n",
      "skin               -2.688   0.045\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized results - non normalized results\")\n",
    "print(\"Time positive = normalized slower \")\n",
    "print(\"Diff positive = normalized improved more\")\n",
    "print()\n",
    "print(tabulate(np.vstack((results[:,0], results[:,3].astype(float)-results_not_norm[:,3].astype(float), results[:,4].astype(float)-results_not_norm[:,4].astype(float))).T, headers=[\"Name\", \"Time Diff\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared = np.vstack((results[:,0], results[:,3].astype(float)-results_not_norm[:,3].astype(float), results[:,4].astype(float)-results_not_norm[:,4].astype(float))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shuttle' 'htru2' 'buzz' 'sensorless' 'cardio' 'skin']\n"
     ]
    }
   ],
   "source": [
    "print(compared[:,0][np.where((compared[:,1].astype(float) < 0) & (compared[:,2].astype(float) > 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also normalizing covertype, malware because "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post normalization stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libdatasets; reload(libdatasets); from libdatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        # Text classification\n",
    "        \n",
    "        (\"newsgroups\", wrap(newsgroups, None)),\n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        \n",
    "        # Image classification\n",
    "        (\"cifar10\", wrap(cifar10, None)),\n",
    "        (\"quickdraw\", wrap(quickdraw, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        \n",
    "        # General\n",
    "        (\"shuttle\", wrap(shuttle, None)),\n",
    "        (\"covertype\", wrap(covertype, None)),\n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"htru2\", wrap(htru2, None)),\n",
    "        (\"malware\", wrap(malware, None)),\n",
    "        (\"bidding\", wrap(bidding, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"bank\", wrap(bank, None)),\n",
    "        (\"buzz\", wrap(buzz, None)),\n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"dota2\", wrap(dota2, None)),\n",
    "        \n",
    "        # Bio\n",
    "        (\"abalone\", wrap(abalone, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),\n",
    "        \n",
    "        # Medical\n",
    "        (\"cardio\", wrap(cardio, None)),\n",
    "        (\"skin\", wrap(skin, None)),\n",
    "        \n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": 0.5,\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "results_p = []\n",
    "for (name, dataset) in matrix['datasets']:\n",
    "    X, y = dataset()\n",
    "    \n",
    "    idx = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    \n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    y_short = y[:10]\n",
    "    X_short = X[:10]\n",
    "    for klass in np.unique(y):\n",
    "        if klass not in y_short:\n",
    "            idx = np.where(y==klass)[0][0]\n",
    "            y_short = np.concatenate((y_short, [y[idx]]), axis=0)\n",
    "            if isinstance(X_short, scipy.sparse.csr_matrix):\n",
    "                X_short = scipy.sparse.vstack((\n",
    "                    X_short, \n",
    "                    X[idx]\n",
    "                ))\n",
    "            else:\n",
    "                X_short = np.concatenate((X_short, [X[idx]]), axis=0)\n",
    "    #print(np.unique(y_short))\n",
    "\n",
    "    clf.fit(X_short, y_short)\n",
    "    start = clf.score(X[-1000:], y[-1000:])\n",
    "    start_t = monotonic()\n",
    "    clf.fit(X[:1000], y[:1000])\n",
    "    time = monotonic() - start_t\n",
    "    final = clf.score(X[-1000:], y[-1000:])\n",
    "    results_p.append([name, start, final, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            Initial acc    Final acc    Time    Diff\n",
      "------------  -------------  -----------  ------  ------\n",
      "newsgroups            0.051        0.434   8.391   0.383\n",
      "rcv1                  0.461        0.908   2.625   0.447\n",
      "webkb                 0.465        0.875   3.063   0.41\n",
      "spamassassin          0.663        0.962   2.234   0.299\n",
      "cifar10               0.15         0.29    7.969   0.14\n",
      "quickdraw             0.491        0.776   0.625   0.285\n",
      "avila                 0.272        0.61    0.219   0.338\n",
      "shuttle               0.856        0.977   0.015   0.121\n",
      "covertype             0.435        0.712   0.328   0.277\n",
      "smartphone            0.526        0.936   0.25    0.41\n",
      "htru2                 0.97         0.98    0.016   0.01\n",
      "malware               0.899        0.975   0.375   0.076\n",
      "bidding               0.897        0.99    0.063   0.093\n",
      "swarm                 0.573        0.943   2.953   0.37\n",
      "bank                  0.87         0.888   0.391   0.018\n",
      "buzz                  0.687        0.916   0.141   0.229\n",
      "sensorless            0.191        0.872   0.328   0.681\n",
      "dota2                 0.512        0.551   9.796   0.039\n",
      "abalone               0.484        0.543   0.391   0.059\n",
      "splice                0.518        0.93    0.734   0.412\n",
      "anuran                0.592        0.937   0.062   0.345\n",
      "cardio                0.578        0.596   0.109   0.018\n",
      "skin                  0.868        0.868   0.031   0\n"
     ]
    }
   ],
   "source": [
    "results_p = np.array(results_p)\n",
    "print(tabulate(np.hstack((results_p, np.expand_dims(results_p[:,2].astype(float)-results_p[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1, webkb, sensorless\n",
    "1, 2, 14\n",
    "4G, 612M, 612M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry run python slurm.py Covertype1d 8 1 0-1; poetry run python slurm.py Smartphone1d 9 1 0-1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry run python nesi.py 8 1 0-1 --dry-run; poetry run python nesi.py 9 1 0-1 --dry-run; poetry run python nesi.py 19 1 0-1 --dry-run;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
