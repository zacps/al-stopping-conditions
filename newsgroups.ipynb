{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "533beb627b1d60f9c83b75f0b98555e948ef78a272412c078d5539dd05fb78ec"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL import batch, uncertainty, density, utils\n",
    "from modAL.models import ActiveLearner\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets, svm, metrics, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from typing import Union, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_split(X, Y, shuffle=True):\n",
    "    \"\"\"\n",
    "    Split data into three sets:\n",
    "    * Labeled training set (0.1)\n",
    "    * Unlabeled training set, to be queried (0.4)\n",
    "    * Labeled test set (0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, shuffle=shuffle, random_state=42)\n",
    "    X_labelled, X_unlabelled, Y_labelled, Y_oracle = train_test_split(X_train, Y_train, test_size=0.95, shuffle=shuffle, random_state=42)\n",
    "\n",
    "    return X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, Y_test\n",
    "\n",
    "def active_learn(X, y, query_strategy) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Perform active learning on the given dataset using a linear SVM model, querying data with the given query strategy.\n",
    "\n",
    "    Returns the accuracy curve.\n",
    "    \"\"\"\n",
    "    X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, Y_test = active_split(X, y, shuffle=True)\n",
    "    learner = ActiveLearner(\n",
    "        estimator=svm.SVC(kernel='rbf', probability=True), \n",
    "        X_training=X_labelled, \n",
    "        y_training=Y_labelled, \n",
    "        query_strategy=query_strategy\n",
    "    )\n",
    "\n",
    "    trained = [len(X_labelled)]\n",
    "    accuracy = [learner.score(X_test, Y_test)]\n",
    "    while len(X_unlabelled) != 0:\n",
    "        query_idx, _ = learner.query(X_unlabelled)\n",
    "        learner.teach(X_unlabelled[query_idx], Y_oracle[query_idx])\n",
    "        X_unlabelled = np.delete(X_unlabelled, query_idx, axis=0)\n",
    "        Y_oracle = np.delete(Y_oracle, query_idx, axis=0)\n",
    "        trained.append(trained[-1]+10)\n",
    "        accuracy.append(learner.score(X_test, Y_test))\n",
    "    return (trained, accuracy)\n",
    "\n",
    "def random_batch(\n",
    "    classifier: sklearn.base.BaseEstimator, \n",
    "    X: Union[list, np.ndarray], \n",
    "    n_instances: int = 1, \n",
    "    random_tie_break: bool = False, \n",
    "    **uncertainty_measure_kwargs\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    idx = np.random.choice(X.shape[0], n_instances)\n",
    "    return (idx, X[idx])\n",
    "\n",
    "def query_logger(\n",
    "    query_func, classifier, X, n_instances=1, **kwargs\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    global confidence_query_log\n",
    "    chosen = query_func(classifier, X, n_instances=n_instances, **kwargs)\n",
    "    confidence_query_log.append(X[chosen])\n",
    "    return chosen\n",
    "\n",
    "def uncertainty_id(clf, X, n_instances=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Sort by the minimum highest confidence labelling.\n",
    "    \"\"\"\n",
    "    return np.argsort(uncertainty.classifier_uncertainty(clf, X) * density.information_density(X))[:n_instances]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_methods = {\n",
    "    #\"uncertainty\": batch.uncertainty_batch_sampling,\n",
    "    \"random\": random_batch,\n",
    "    #\"margin\": uncertainty.margin_sampling,\n",
    "    #\"entropy\": uncertainty.entropy_sampling,\n",
    "    #\"uncertainty_id\": uncertainty_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.fetch_20newsgroups_vectorized(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"data\"]\n",
    "y = dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18846, 101631)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {name: active_learn(X, y, partial(method, n_instances=10)) for name, method in query_methods.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for name, result in results.items():\n",
    "    ax.plot(result[0], result[1], label=name)\n",
    "    ax.set_ylim(0.9, 1)\n",
    "fig.legend();"
   ]
  }
 ]
}