{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libactive import active_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.utils import check_random_state\n",
    "import scipy\n",
    "from libutil import out_dir\n",
    "import os\n",
    "import libdatasets\n",
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_passive(datasets, runs):\n",
    "    for name, dataset in datasets:\n",
    "        if name == 'newsgroups':\n",
    "            continue\n",
    "        print(name)\n",
    "        fname = f\"{out_dir()}{os.path.sep}passive{os.path.sep}{name}.pickle\"\n",
    "        try:\n",
    "            with open(fname, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "                print(f\"Have results for {name}\")\n",
    "                if all([run in results.keys() for run in runs]):\n",
    "                    continue\n",
    "        except (FileNotFoundError, EOFError):\n",
    "            results = {}\n",
    "\n",
    "\n",
    "        for run in runs:\n",
    "            print(f\"  {run}\")\n",
    "            if run in results.keys():\n",
    "                continue\n",
    "                \n",
    "            X,y = dataset()\n",
    "\n",
    "            X_labelled, X_unlabelled, y_labelled, y_oracle, X_test, y_test = active_split(\n",
    "                X, y, labeled_size=10, test_size=0.5, random_state=check_random_state(run), ensure_y=True\n",
    "\n",
    "            )\n",
    "            if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "                X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "            else:\n",
    "                X = np.concatenate((X_labelled, X_unlabelled))\n",
    "            y = np.concatenate((y_labelled, y_oracle))\n",
    "\n",
    "            clf = SVC(probability=True, kernel='linear')\n",
    "            clf.fit(X, y)\n",
    "            predicted = clf.predict(X_test)\n",
    "            predict_proba = clf.predict_proba(X_test)\n",
    "            unique_labels = np.unique(y_labelled)\n",
    "\n",
    "            if len(unique_labels) > 2 or len(unique_labels.shape) > 1:\n",
    "                roc_auc = roc_auc_score(\n",
    "                    y_test, predict_proba, multi_class=\"ovr\"\n",
    "                )\n",
    "            else:\n",
    "                roc_auc = roc_auc_score(\n",
    "                    y_test, predict_proba[:, 1]\n",
    "            )\n",
    "\n",
    "            results[run] = [\n",
    "                accuracy_score(y_test, predicted),\n",
    "                f1_score(\n",
    "                    y_test,\n",
    "                    predicted,\n",
    "                    average=\"micro\" if len(unique_labels) > 2 else \"binary\",\n",
    "                    pos_label=unique_labels[1] if len(unique_labels) <= 2 else 1,\n",
    "                ),\n",
    "                roc_auc\n",
    "            ]\n",
    "\n",
    "            with open(fname, \"wb\") as f:\n",
    "                pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesi_noise import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key(dataset):\n",
    "    return dataset[1]()[0].shape[0]\n",
    "\n",
    "datasets = sorted(matrix['datasets'], key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splice\n",
      "webkb\n",
      "spamassassin\n",
      "anuran\n",
      "smartphone\n",
      "newsgroups\n",
      "avila\n",
      "swarm\n",
      "sensorless\n",
      "rcv1\n"
     ]
    }
   ],
   "source": [
    "for name, _ in datasets:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splice\n",
      "Have results for splice\n",
      "webkb\n",
      "Have results for webkb\n",
      "spamassassin\n",
      "Have results for spamassassin\n",
      "anuran\n",
      "Have results for anuran\n",
      "smartphone\n",
      "Have results for smartphone\n",
      "avila\n",
      "Have results for avila\n",
      "swarm\n",
      "Have results for swarm\n",
      "sensorless\n",
      "Have results for sensorless\n",
      "rcv1\n",
      "  0\n"
     ]
    }
   ],
   "source": [
    "run_passive(datasets, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
