{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libactive import active_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.utils import check_random_state\n",
    "import scipy\n",
    "from libutil import out_dir\n",
    "import os\n",
    "import libdatasets\n",
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_passive(datasets, runs):\n",
    "    for name, dataset in datasets[1:]:\n",
    "        if name != 'anuran':\n",
    "            continue\n",
    "        print(name)\n",
    "        fname = f\"{out_dir()}{os.path.sep}passive{os.path.sep}{name}.pickle\"\n",
    "        try:\n",
    "            with open(fname, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "                print(results)\n",
    "                if all([run in results.keys() for run in runs]):\n",
    "                    return [\n",
    "                        [\n",
    "                            np.min([result[i] for result in results.values()]),\n",
    "                             np.mean([result[i] for result in results.values()]),\n",
    "                             np.max([result[i] for result in results.values()])\n",
    "                        ] for i in range(3)\n",
    "                    ]\n",
    "        except (FileNotFoundError, EOFError):\n",
    "            results = {}\n",
    "\n",
    "\n",
    "        for run in runs:\n",
    "            print(f\"  {run}\")\n",
    "            if run in results.keys():\n",
    "                continue\n",
    "                \n",
    "            X,y = dataset()\n",
    "\n",
    "            X_labelled, X_unlabelled, y_labelled, y_oracle, X_test, y_test = active_split(\n",
    "                X, y, labeled_size=10, test_size=0.5, random_state=check_random_state(run), ensure_y=True\n",
    "\n",
    "            )\n",
    "            if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "                X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "            else:\n",
    "                X = np.concatenate((X_labelled, X_unlabelled))\n",
    "            y = np.concatenate((y_labelled, y_oracle))\n",
    "\n",
    "            clf = SVC(probability=True, kernel='linear')\n",
    "            clf.fit(X, y)\n",
    "            predicted = clf.predict(X_test)\n",
    "            predict_proba = clf.predict_proba(X_test)\n",
    "            unique_labels = np.unique(y_labelled)\n",
    "\n",
    "            if len(unique_labels) > 2 or len(unique_labels.shape[0]) > 1:\n",
    "                roc_auc = roc_auc_score(\n",
    "                    y_test, predict_proba, multi_class=\"ovr\"\n",
    "                )\n",
    "            else:\n",
    "                roc_auc = roc_auc_score(\n",
    "                    y_test, predict_proba[:, 1]\n",
    "            )\n",
    "\n",
    "            results[run] = [\n",
    "                accuracy_score(y_test, predicted),\n",
    "                f1_score(\n",
    "                    y_test,\n",
    "                    predicted,\n",
    "                    average=\"micro\" if len(unique_labels) > 2 else \"binary\",\n",
    "                    pos_label=unique_labels[1] if len(unique_labels) <= 2 else 1,\n",
    "                ),\n",
    "                roc_auc\n",
    "            ]\n",
    "\n",
    "            with open(fname, \"wb\") as f:\n",
    "                pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesi_noise import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anuran\n",
      "{0: [0.9663702056698166, 0.9663702056698166, 0.9962899788694562], 1: [0.9677598665925514, 0.9677598665925514, 0.9871650626295676], 2: [0.9644246803779878, 0.9644246803779878, 0.994715588866147], 3: [0.9635908838243469, 0.9635908838243469, 0.9960201815025295], 4: [0.9647026125625348, 0.9647026125625348, 0.9953732278752536], 5: [0.9694274596998332, 0.9694274596998332, 0.995087486448907], 6: [0.9608115619788772, 0.9608115619788772, 0.9958793817354522], 7: [0.9680377987770984, 0.9680377987770984, 0.9953472068189424], 8: [0.9638688160088938, 0.9638688160088938, 0.9974182937637959], 9: [0.9638688160088938, 0.9638688160088938, 0.9967435733260384]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9608115619788772, 0.9652862701500833, 0.9694274596998332],\n",
       " [0.9608115619788772, 0.9652862701500833, 0.9694274596998332],\n",
       " [0.9871650626295676, 0.9950039981836089, 0.9974182937637959]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_passive(matrix['datasets'], range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
