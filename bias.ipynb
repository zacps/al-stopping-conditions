{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from importlib import reload\n",
    "from functools import partial, lru_cache\n",
    "import itertools\n",
    "from time import monotonic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import delayed\n",
    "from modAL import batch\n",
    "from art.metrics import empirical_robustness\n",
    "from art.attacks.evasion import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnSVC\n",
    "from sklearn.metrics.pairwise import paired_distances, euclidean_distances\n",
    "import scipy\n",
    "from tvregdiff.tvregdiff import TVRegDiff\n",
    "from tabulate import tabulate\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import libactive\n",
    "import libadversarial\n",
    "import libstop\n",
    "from libactive import MyActiveLearner, active_split\n",
    "from libadversarial import adversarial, uncertainty, random_batch, uncertainty_stop\n",
    "from libutil import ProgressParallel\n",
    "from libdatasets import *\n",
    "import librun\n",
    "from librun import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libdatasets; reload(libdatasets); from libdatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        #(\"newsgroups\", wrap(newsgroups, None)),\n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),        \n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": {\n",
    "            \"newsgroups_faith\": 500,\n",
    "            \"newsgroups_graphics\": 500,\n",
    "            \"newsgroups_hardware\": 500,\n",
    "            \"newsgroups_sports_crypto\": 500,\n",
    "            \"*\": 0.5\n",
    "        },\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(libactive); from libactive import active_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "import operator\n",
    "import nesi_bias\n",
    "import traceback\n",
    "reload(nesi_bias)\n",
    "reload(libactive); from libactive import active_split\n",
    "from nesi_bias import bias\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "def func(amount):\n",
    "    results = []\n",
    "    for (name, dataset) in matrix['datasets']:\n",
    "        #print(f\"{name}\")\n",
    "        X, y = dataset()\n",
    "\n",
    "        try:\n",
    "            X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, y_test = active_split(\n",
    "                *dataset(), mutator=partial(bias, amount=amount), test_size=0.5, labeled_size=10, shuffle=True, random_state=np.random\n",
    "            )\n",
    "            assert X_unlabelled.shape[0] >= 1490, \"unlabelled pool too small\"\n",
    "        except Exception as e:\n",
    "            #print(f\"Could not split: {e}\")\n",
    "            #traceback.print_exc()\n",
    "            results.append([name, 0,0,0])\n",
    "            continue\n",
    "\n",
    "        if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "            X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "        else:\n",
    "            X = np.concatenate((X_labelled, X_unlabelled))\n",
    "        y = np.concatenate((Y_labelled, Y_oracle))\n",
    "\n",
    "\n",
    "        clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "        clf.fit(X_labelled, Y_labelled)\n",
    "        start = clf.score(X_test, y_test)\n",
    "        start_t = monotonic()\n",
    "        clf.fit(X[:1000], y[:1000])\n",
    "        time = monotonic() - start_t\n",
    "        final = clf.score(X_test, y_test)\n",
    "        results.append([name, start, final, time])\n",
    "        \n",
    "    results = np.array(results)\n",
    "    print(tabulate(np.hstack((results, np.expand_dims(results[:,2].astype(float)-results[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount=0.1\n",
      "Name            Initial acc    Final acc    Time      Diff\n",
      "------------  -------------  -----------  ------  --------\n",
      "rcv1              0.474062      0.879788   2.687  0.405726\n",
      "webkb             0             0          0      0\n",
      "spamassassin      0             0          0      0\n",
      "avila             0.0959364     0.526356   0.282  0.43042\n",
      "smartphone        0             0          0      0\n",
      "swarm             0.51016       0.943538   4.469  0.433378\n",
      "sensorless        0.155426      0.799761   0.312  0.644334\n",
      "splice            0             0          0      0\n",
      "anuran            0.673708      0.948305   0.078  0.274597\n",
      "\n",
      "amount=0.2\n",
      "Name            Initial acc    Final acc    Time       Diff\n",
      "------------  -------------  -----------  ------  ---------\n",
      "rcv1               0.473423     0.884803   2.984  0.41138\n",
      "webkb              0            0          0      0\n",
      "spamassassin       0            0          0      0\n",
      "avila              0.346751     0.526164   0.281  0.179413\n",
      "smartphone         0.52123      0.939971   0.266  0.418741\n",
      "swarm              0.672635     0.735676   2.938  0.0630413\n",
      "sensorless         0.237737     0.840608   0.422  0.602871\n",
      "splice             0            0          0      0\n",
      "anuran             0.662034     0.944969   0.094  0.282935\n",
      "\n",
      "amount=0.3\n",
      "Name            Initial acc    Final acc    Time      Diff\n",
      "------------  -------------  -----------  ------  --------\n",
      "rcv1               0.474017     0.873776   2.672  0.399759\n",
      "webkb              0            0          0      0\n",
      "spamassassin       0            0          0      0\n",
      "avila              0            0          0      0\n",
      "smartphone         0.434663     0.770132   0.297  0.335469\n",
      "swarm              0.573534     0.764574   2.172  0.191039\n",
      "sensorless         0.191181     0.796548   0.312  0.605367\n",
      "splice             0            0          0      0\n",
      "anuran             0.542524     0.931351   0.047  0.388827\n",
      "\n",
      "amount=0.4\n",
      "Name            Initial acc    Final acc    Time      Diff\n",
      "------------  -------------  -----------  ------  --------\n",
      "rcv1               0.616899     0.871422   2.515  0.254523\n",
      "webkb              0            0          0      0\n",
      "spamassassin       0.6692       0.969927   2.391  0.300727\n",
      "avila              0.231263     0.47326    0.282  0.241997\n",
      "smartphone         0.491032     0.782028   0.281  0.290996\n",
      "swarm              0.596935     0.723851   1.938  0.126915\n",
      "sensorless         0.211964     0.72938    0.313  0.517416\n",
      "splice             0            0          0      0\n",
      "anuran             0.282379     0.955531   0.078  0.673152\n",
      "\n",
      "amount=0.5\n",
      "Name            Initial acc    Final acc    Time      Diff\n",
      "------------  -------------  -----------  ------  --------\n",
      "rcv1               0.528004     0.873073   2.735  0.345069\n",
      "webkb              0            0          0      0\n",
      "spamassassin       0.768672     0.959352   2.047  0.190681\n",
      "avila              0.138969     0.465785   0.265  0.326816\n",
      "smartphone         0.414165     0.776903   0.313  0.362738\n",
      "swarm              0.614923     0.782478   3.032  0.167555\n",
      "sensorless         0.1839       0.799829   0.312  0.615929\n",
      "splice             0            0          0      0\n",
      "anuran             0.576987     0.831017   0.047  0.25403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amounts = [0.1,0.2,0.3,0.4,0.5]\n",
    "for amount in amounts:\n",
    "    print(f\"amount={amount}\")\n",
    "    func(amount)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rcv1, avila, swarm, sensorless, anuran**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def func():\n",
    "    results = []\n",
    "    for (name, dataset) in matrix['datasets']:\n",
    "        #print(f\"{name}\")\n",
    "        X, y = dataset()\n",
    "\n",
    "        try:\n",
    "            X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, y_test = active_split(\n",
    "                *dataset(), mutator=lambda *args, **kwargs: args, test_size=0.5, labeled_size=10, shuffle=True, random_state=np.random\n",
    "            )\n",
    "            assert X_unlabelled.shape[0] >= 1490, \"unlabelled pool too small\"\n",
    "        except Exception as e:\n",
    "            #print(f\"Could not split: {e}\")\n",
    "            #traceback.print_exc()\n",
    "            results.append([name, 0,0,0])\n",
    "            continue\n",
    "\n",
    "        if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "            X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "        else:\n",
    "            X = np.concatenate((X_labelled, X_unlabelled))\n",
    "        y = np.concatenate((Y_labelled, Y_oracle))\n",
    "\n",
    "\n",
    "        clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "        clf.fit(X_labelled, Y_labelled)\n",
    "        start = clf.score(X_test, y_test)\n",
    "        start_t = monotonic()\n",
    "        clf.fit(X[:1000], y[:1000])\n",
    "        time = monotonic() - start_t\n",
    "        final = clf.score(X_test, y_test)\n",
    "        results.append([name, start, final, time])\n",
    "        \n",
    "    results = np.array(results)\n",
    "    print(tabulate(np.hstack((results, np.expand_dims(results[:,2].astype(float)-results[:,1].astype(float), axis=1))), headers=[\"Name\", \"Initial acc\", \"Final acc\", \"Time\", \"Diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            Initial acc    Final acc    Time      Diff\n",
      "------------  -------------  -----------  ------  --------\n",
      "rcv1               0.474798     0.903478   2.641  0.42868\n",
      "webkb              0.451905     0.869048   3.562  0.417143\n",
      "spamassassin       0.752148     0.965631   2.985  0.213483\n",
      "avila              0.12258      0.5507     0.281  0.42812\n",
      "smartphone         0.566984     0.943448   0.313  0.376464\n",
      "swarm              0.694704     0.941123   4      0.246419\n",
      "sensorless         0.16616      0.879132   0.328  0.712972\n",
      "splice             0.590596     0.9279     0.766  0.337304\n",
      "anuran             0.738188     0.935242   0.062  0.197054\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
