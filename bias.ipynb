{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from importlib import reload\n",
    "from functools import partial, lru_cache\n",
    "import itertools\n",
    "from time import monotonic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import delayed\n",
    "from modAL import batch\n",
    "from art.metrics import empirical_robustness\n",
    "from art.attacks.evasion import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnSVC\n",
    "from sklearn.metrics.pairwise import paired_distances, euclidean_distances\n",
    "import scipy\n",
    "from tvregdiff.tvregdiff import TVRegDiff\n",
    "from tabulate import tabulate\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import libactive\n",
    "import libadversarial\n",
    "import libstop\n",
    "from libactive import MyActiveLearner, active_split\n",
    "from libadversarial import adversarial, uncertainty, random_batch, uncertainty_stop\n",
    "from libutil import ProgressParallel\n",
    "from libdatasets import *\n",
    "import librun\n",
    "from librun import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libdatasets; reload(libdatasets); from libdatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        (\"newsgroups\", wrap(newsgroups, None)),\n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),        \n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": {\n",
    "            \"newsgroups_faith\": 500,\n",
    "            \"newsgroups_graphics\": 500,\n",
    "            \"newsgroups_hardware\": 500,\n",
    "            \"newsgroups_sports_crypto\": 500,\n",
    "            \"*\": 0.5\n",
    "        },\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(libactive); from libactive import active_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroups\n",
      "rcv1\n",
      "webkb\n",
      "spamassassin\n",
      "avila\n",
      "  Start split\n",
      "[    0     1     3 ... 10428 10430 10432]\n",
      "unique ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'W' 'X' 'Y']\n",
      "oracle (array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'W', 'X', 'Y'],\n",
      "      dtype=object), array([ 925,   33, 5303, 5640,  536,   37,  184,   32,   17,  186,  114],\n",
      "      dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zac\\Programming\\python\\research\\libactive.py:74: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if klass not in Y_labelled:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3bb59455e2a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Start split\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, y_test = active_split(\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     )\n",
      "\u001b[1;32m~\\Programming\\python\\research\\libactive.py\u001b[0m in \u001b[0;36mactive_split\u001b[1;34m(X, Y, test_size, labeled_size, shuffle, ensure_y, random_state, mutator, config_str, i)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mY_labelled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;31m# First value chosen is effectively constant random as the dataset is shuffled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_oracle\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mklass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mY_labelled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_labelled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY_oracle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import monotonic\n",
    "import nesi_bias\n",
    "reload(nesi_bias)\n",
    "reload(libactive); from libactive import active_split\n",
    "from nesi_bias import bias\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "results_nn = []\n",
    "for (name, dataset) in matrix['datasets']:\n",
    "    print(f\"{name}\")\n",
    "    X, y = dataset()\n",
    "\n",
    "    if isinstance(X, scipy.sparse.csr_matrix):\n",
    "        results_nn.append([name, 0,0,0])\n",
    "        continue\n",
    "\n",
    "    print(\"  Start split\")\n",
    "    X_labelled, X_unlabelled, Y_labelled, Y_oracle, X_test, y_test = active_split(\n",
    "        *dataset(), mutator=partial(bias, amount=0.5), test_size=0.5, labeled_size=10, shuffle=True, random_state=np.random\n",
    "    )\n",
    "    print(\"  End split\")\n",
    "\n",
    "    if isinstance(X_labelled, scipy.sparse.csr_matrix):\n",
    "        X = scipy.sparse.vstack((X_labelled, X_unlabelled))\n",
    "    else:\n",
    "        X = np.concatenate((X_labelled, X_unlabelled))\n",
    "    y = np.concatenate((Y_labelled, Y_oracle))\n",
    "\n",
    "    \n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    y_short = y[:10]\n",
    "    X_short = X[:10]\n",
    "    for klass in np.unique(y):\n",
    "        if klass not in y_short:\n",
    "            idx = np.where(y==klass)[0][0]\n",
    "            y_short = np.concatenate((y_short, [y[idx]]), axis=0)\n",
    "            if isinstance(X_short, scipy.sparse.csr_matrix):\n",
    "                X_short = scipy.sparse.vstack((\n",
    "                    X_short, \n",
    "                    X[idx]\n",
    "                ))\n",
    "            else:\n",
    "                X_short = np.concatenate((X_short, [X[idx]]), axis=0)\n",
    "    #print(np.unique(y_short))\n",
    "\n",
    "    print(\"  Start short fit\")\n",
    "    clf.fit(X_short, y_short)\n",
    "    print(\"  Stop short fit\")\n",
    "    start = clf.score(X_test, y_test)\n",
    "    start_t = monotonic()\n",
    "    print(\"  Start long fit\")\n",
    "    clf.fit(X, y)\n",
    "    print(\"  Stop long fit\")\n",
    "    time = monotonic() - start_t\n",
    "    final = clf.score(X_test, y_test)\n",
    "    results_nn.append([name, start, final, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
