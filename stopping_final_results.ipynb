{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from importlib import reload\n",
    "from functools import partial, lru_cache\n",
    "import itertools\n",
    "from time import monotonic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import delayed\n",
    "from modAL import batch\n",
    "from art.metrics import empirical_robustness\n",
    "from art.attacks.evasion import *\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnSVC\n",
    "from sklearn.metrics.pairwise import paired_distances, euclidean_distances\n",
    "import scipy\n",
    "from tvregdiff.tvregdiff import TVRegDiff\n",
    "from tabulate import tabulate\n",
    "\n",
    "from ipynb.fs.defs import Bias\n",
    "from ipynb.fs.defs.Datasets import generateData_twoPills_2D, generateData_twoPills_noNoise_2D, plot_dataset_2D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import libactive\n",
    "import libadversarial\n",
    "import libstop\n",
    "from libactive import MyActiveLearner, active_split\n",
    "from libadversarial import adversarial, uncertainty, random_batch, uncertainty_stop\n",
    "from libutil import ProgressParallel\n",
    "from libdatasets import *\n",
    "import librun\n",
    "from librun import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libdatasets; reload(libdatasets); from libdatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(func, *args, **kwargs):\n",
    "    wrapper = lambda: lru_cache()(func)(*args, **kwargs)\n",
    "    for attr in [attr for attr in dir(func) if not attr.startswith('__')]:\n",
    "        setattr(wrapper, attr, getattr(func, attr))\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset selection criteria\n",
    "\n",
    "* More than 3000 instances\n",
    "* More than 2 features\n",
    "* No missing values\n",
    "* Ideally easy to extract & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    # Dataset fetchers should cache if possible\n",
    "    # Lambda wrapper required for function to be pickleable (sent to other threads via joblib)\n",
    "    \"datasets\": [\n",
    "        # Text classification\n",
    "        (\"newsgroups\", wrap(newsgroups, None)),\n",
    "        (\"rcv1\", wrap(rcv1, None)),\n",
    "        (\"webkb\", wrap(webkb, None)),\n",
    "        (\"spamassassin\", wrap(spamassassin, None)),\n",
    "        \n",
    "        # Image classification\n",
    "        (\"cifar10\", wrap(cifar10, None)),\n",
    "        (\"quickdraw\", wrap(quickdraw, None)),\n",
    "        (\"avila\", wrap(avila, None)),\n",
    "        \n",
    "        # General\n",
    "        (\"shuttle\", wrap(shuttle, None)),\n",
    "        #(\"covertype\", wrap(covertype, None)), # fit takes a million years (1233s for 1000 instances)\n",
    "        (\"smartphone\", wrap(smartphone, None)),\n",
    "        (\"htru2\", wrap(htru2, None)),\n",
    "        #(\"malware\", wrap(malware, None)), # MALWARE FIT DID NOT FINISH (07:30:30.xxx CPU time)\n",
    "        (\"bidding\", wrap(bidding, None)),\n",
    "        (\"swarm\", wrap(swarm, None)),\n",
    "        (\"bank\", wrap(bank, None)),\n",
    "        (\"buzz\", wrap(buzz, None)), # Slow fit times\n",
    "        (\"sensorless\", wrap(sensorless, None)),\n",
    "        (\"dota2\", wrap(dota2, None)),\n",
    "        \n",
    "        # Bio\n",
    "        (\"abalone\", wrap(abalone, None)),\n",
    "        (\"splice\", wrap(splice, None)),\n",
    "        (\"anuran\", wrap(anuran, None)),\n",
    "        \n",
    "        # Medical\n",
    "        (\"cardio\", wrap(cardio, None)),\n",
    "        (\"skin\", wrap(skin, None)),\n",
    "        \n",
    "    ],\n",
    "    \"dataset_mutators\": {\n",
    "        \"none\": (lambda *x, **kwargs: x),\n",
    "    },\n",
    "    \"methods\": [\n",
    "        (\"uncertainty\", partial(uncertainty_stop, n_instances=10)),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        \"svm-linear\"\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"dataset_size\": 1000,\n",
    "        \"labelled_size\": 10,\n",
    "        \"test_size\": 0.5,\n",
    "        \"n_runs\": 10,\n",
    "        \"ret_classifiers\": True,\n",
    "        \"ensure_y\": True,\n",
    "        \"stop_info\": True,\n",
    "        \"aggregate\": False,\n",
    "        \"stop_function\": (\"len1000\", lambda learner: learner.y_training.shape[0] >= 1000),\n",
    "        \"pool_subsample\": 1000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_metrics = [\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    \n",
    "    \"uncertainty_average\",\n",
    "    \"uncertainty_min\",\n",
    "    \"uncertainty_max\",\n",
    "    \"uncertainty_variance\",\n",
    "    \"uncertainty_average_selected\",\n",
    "    \"uncertainty_min_selected\",\n",
    "    \"uncertainty_max_selected\",\n",
    "    \"uncertainty_variance_selected\",\n",
    "    \"entropy_max\",\n",
    "    \"n_support\",\n",
    "    \"contradictory_information\",\n",
    "    # slow\n",
    "    #\"expected_error\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                     Instances    Classes    Features  Most common class           Least common class    Domain\n",
      "------------------------  -----------  ---------  ----------  --------------------------  --------------------  --------\n",
      "newsgroups_faith                 1796          2      125145  15 56%                      0 44%                 nlp\n",
      "newsgroups_graphics              1961          2      125145  5 50%                       1 50%                 nlp\n",
      "newsgroups_hardware              1967          2      125145  2 50%                       3 50%                 nlp\n",
      "newsgroups_sports_crypto         1985          2      125145  9 50%                       11 50%                nlp\n",
      "rcv1                           804414          2       47236  0 53%                       1 47%                 nlp\n",
      "webkb                            4199          4       22981  student 39%                 project 12%           nlp\n",
      "spamassassin                     6051          2       50196  ham 69%                     spam 31%              nlp\n",
      "cifar10                         60000         10        3072  0 10%                       0 10%                 image\n",
      "quickdraw                      556217          4         784  4 29%                       2 22%                 image\n",
      "avila                           20867         12          10  A 41%                       B 0%                  general\n",
      "shuttle                         58000          2          10  True 79%                    False 21%             general\n",
      "smartphone                      10927         12         561  5 18%                       8 0%                  general\n",
      "htru2                           17898          2           8  0 91%                       1 9%                  physical\n",
      "bidding                          6321          2       20719  0 89%                       1 11%                 general\n",
      "swarm                           24015          2        2400  0 50%                       1 50%                 general\n",
      "bank                            45211          2        9541  no 88%                      yes 12%               general\n",
      "buzz                             1000          2          96  1.0 63%                     0.0 37%               general\n",
      "sensorless                      58509         11          48  1 9%                        1 9%                  general\n",
      "dota2                          102944          2         116  1 53%                       -1 47%                general\n",
      "abalone                          4177          3           8  M 37%                       F 31%                 general\n",
      "splice                           3190          3         287  N 52%                       EI 24%                general\n",
      "anuran                           7195         10          22  AdenomeraHylaedactylus 48%  Rhinellagranulosa 1%  general\n",
      "cardio                          70000          2           3  0 50%                       1 50%                 general\n",
      "skin                           245057          2           3  2 79%                       1 21%                 general\n"
     ]
    }
   ],
   "source": [
    "libdatasets.dataset_summary([data[0] for data in matrix['datasets']], [data[1] for data in matrix['datasets']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\zac\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "results = []\n",
    "for (name, dataset) in matrix['datasets']:\n",
    "    #if name != \"spamassassin\": continue\n",
    "    X, y = dataset()\n",
    "    \n",
    "    idx = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    \n",
    "    clf = SVC(kernel='linear', probability=True)\n",
    "\n",
    "    y_short = y[:10]\n",
    "    X_short = X[:10]\n",
    "    for klass in np.unique(y):\n",
    "        if klass not in y_short:\n",
    "            idx = np.where(y==klass)[0][0]\n",
    "            y_short = np.concatenate((y_short, [y[idx]]), axis=0)\n",
    "            if isinstance(X_short, scipy.sparse.csr_matrix):\n",
    "                X_short = scipy.sparse.vstack((\n",
    "                    X_short, \n",
    "                    X[idx]\n",
    "                ))\n",
    "            else:\n",
    "                X_short = np.concatenate((X_short, [X[idx]]), axis=0)\n",
    "    #print(np.unique(y_short))\n",
    "\n",
    "    clf.fit(X_short, y_short)\n",
    "    start = clf.score(X[-1000:], y[-1000:])\n",
    "    clf.fit(X[:1000], y[:1000])\n",
    "    final = clf.score(X[-1000:], y[-1000:])\n",
    "    results.append([start, final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                        Start    Final    Change\n",
      "------------------------  -------  -------  --------\n",
      "newsgroups_faith            0.438    0.928     0.49\n",
      "newsgroups_graphics         0.614    0.893     0.279\n",
      "newsgroups_hardware         0.564    0.889     0.325\n",
      "newsgroups_sports_crypto    0.484    0.985     0.501\n",
      "rcv1                        0.533    0.914     0.381\n",
      "webkb                       0.382    0.866     0.484\n",
      "spamassassin                0.736    0.974     0.238\n",
      "cifar10                     0.133    0.312     0.179\n",
      "quickdraw                   0.585    0.757     0.172\n",
      "avila                       0.427    0.565     0.138\n",
      "shuttle                     0.791    0.985     0.194\n",
      "smartphone                  0.663    0.945     0.282\n",
      "htru2                       0.895    0.982     0.087\n",
      "bidding                     0.885    0.992     0.107\n",
      "swarm                       0.488    0.959     0.471\n",
      "bank                        0.835    0.883     0.048\n",
      "buzz                        0.959    0.987     0.028\n",
      "sensorless                  0.103    0.414     0.311\n",
      "dota2                       0.513    0.548     0.035\n",
      "abalone                     0.453    0.504     0.051\n",
      "splice                      0.512    0.913     0.401\n",
      "anuran                      0.633    0.929     0.296\n",
      "cardio                      0.627    0.626    -0.001\n",
      "skin                        0.89     0.882    -0.008\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(zip([x[0] for x in matrix['datasets']], [r[0] for r in results], [r[1] for r in results], [r[1]-r[0] for r in results]), headers=[\"Name\", \"Start\", \"Final\", \"Change\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name                        Start    Final    Change\n",
    "\n",
    "------------------------  -------  -------  --------\n",
    "\n",
    "newsgroups_faith            0.438    0.928     0.49\n",
    "\n",
    "newsgroups_graphics         0.614    0.893     0.279\n",
    "\n",
    "newsgroups_hardware         0.564    0.889     0.325\n",
    "\n",
    "newsgroups_sports_crypto    0.484    0.985     0.501\n",
    "\n",
    "rcv1                        0.533    0.914     0.381\n",
    "\n",
    "webkb                       0.382    0.866     0.484\n",
    "\n",
    "spamassassin                0.736    0.974     0.238\n",
    "\n",
    "cifar10                     0.133    0.312     0.179\n",
    "\n",
    "quickdraw                   0.585    0.757     0.172\n",
    "\n",
    "avila                       0.427    0.565     0.138\n",
    "\n",
    "shuttle                     0.791    0.985     0.194\n",
    "\n",
    "smartphone                  0.663    0.945     0.282\n",
    "\n",
    "~~htru2                       0.895    0.982     0.087~~\n",
    "\n",
    "bidding                     0.885    0.992     0.107\n",
    "\n",
    "swarm                       0.488    0.959     0.471\n",
    "\n",
    "bank                        0.835    0.883     0.048\n",
    "\n",
    "buzz                        0.959    0.987     0.028\n",
    "\n",
    "sensorless                  0.103    0.414     0.311\n",
    "\n",
    "dota2                       0.513    0.548     0.035\n",
    "\n",
    "abalone                     0.453    0.504     0.051\n",
    "\n",
    "splice                      0.512    0.913     0.401\n",
    "\n",
    "anuran                      0.633    0.929     0.296\n",
    "\n",
    "~~cardio                      0.627    0.626    -0.001~~\n",
    "\n",
    "~~skin                        0.89     0.882    -0.008~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'librun' from 'C:\\\\Users\\\\Zac\\\\Programming\\\\python\\\\research\\\\librun.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(librun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = librun.run(matrix, metrics=capture_metrics, force_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learn to 1,000 instances. \n",
    "* Use a pool of as much data as possible for the dataset. \n",
    "* Start at 10+ensure_y instances\n",
    "* Use a validation set size of ???\n",
    "* Randomise the split each run, but use a seeded generator\n",
    "* Report results using autorank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
